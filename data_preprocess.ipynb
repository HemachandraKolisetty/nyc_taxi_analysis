{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary Preprocess code\n",
    "def plot_df_column_distribution(df, column, sample_frac=0.05):\n",
    "    \"\"\"\n",
    "    Plot the distribution of a column from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column (str): The column to plot.\n",
    "        sample_frac (float): Fraction of data to sample (default: 0.05 = 5%).\n",
    "    \"\"\"\n",
    "    if sample_frac < 1.0:\n",
    "        df = df.sample(frac=sample_frac, random_state=42)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[column], kde=True, bins=100)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, cols, factor=1.5):\n",
    "    \"\"\"\n",
    "    Removes rows with outliers in specified columns using the IQR method.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        cols (list): List of column names to check for outliers.\n",
    "        factor (float): Multiplier for IQR (default=1.5). Use 3 for more aggressive filtering.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def data_preprocess(dir: str, train_b: bool):\n",
    "    if train_b:\n",
    "        all_files = glob.glob(os.path.join(dir, 'yellow_tripdata_2023-*.parquet'))\n",
    "    else:\n",
    "        all_files = glob.glob(os.path.join(dir, 'yellow_tripdata_2024-*.parquet'))\n",
    "        \n",
    "    df_list = [pd.read_parquet(file) for file in all_files]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    df = df[['PULocationID', 'DOLocationID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance', 'total_amount']]\n",
    "    df['PULocationID'] = pd.to_numeric(df['PULocationID'], downcast='integer')\n",
    "    df['DOLocationID'] = pd.to_numeric(df['DOLocationID'], downcast='integer')\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['time_bin'] = df['tpep_pickup_datetime'].dt.floor(f'{60}min')\n",
    "    df['day_of_week'] = df['time_bin'].dt.dayofweek\n",
    "    df['day_of_month'] = df['time_bin'].dt.day\n",
    "    df['hour'] = df['time_bin'].dt.hour\n",
    "    df['month'] = df['time_bin'].dt.month\n",
    "    df['weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    df['travel_time'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds()\n",
    "    df = df.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'time_bin'])\n",
    "    \n",
    "    # Remove rows with negative travel time or negative total amount\n",
    "    df = df[df['total_amount'] > 0]\n",
    "    df = df[df['travel_time'] > 0]\n",
    "    \n",
    "    # Remove outliers wrt total amount and travel time\n",
    "    df = remove_outliers_iqr(df, ['total_amount', 'travel_time'])\n",
    "    \n",
    "    # Save the preprocessed data as csv\n",
    "    if train_b:\n",
    "        df.to_csv('data/train.csv', index=False)\n",
    "    else:\n",
    "        df.to_csv('data/test.csv', index=False)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the training and testing data\n",
    "\n",
    "df_train = data_preprocess('data/train', True)\n",
    "df_test = data_preprocess('data/test', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32606864 entries, 0 to 38310225\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   PULocationID   int16  \n",
      " 1   DOLocationID   int16  \n",
      " 2   trip_distance  float64\n",
      " 3   total_amount   float64\n",
      " 4   day_of_week    int32  \n",
      " 5   day_of_month   int32  \n",
      " 6   hour           int32  \n",
      " 7   month          int32  \n",
      " 8   weekend        int64  \n",
      " 9   travel_time    float64\n",
      "dtypes: float64(3), int16(2), int32(4), int64(1)\n",
      "memory usage: 1.8 GB\n",
      "None\n",
      "Testing data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35066064 entries, 0 to 41169719\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   PULocationID   int16  \n",
      " 1   DOLocationID   int16  \n",
      " 2   trip_distance  float64\n",
      " 3   total_amount   float64\n",
      " 4   day_of_week    int32  \n",
      " 5   day_of_month   int32  \n",
      " 6   hour           int32  \n",
      " 7   month          int32  \n",
      " 8   weekend        int64  \n",
      " 9   travel_time    float64\n",
      "dtypes: float64(3), int16(2), int32(4), int64(1)\n",
      "memory usage: 2.0 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print info\n",
    "\n",
    "print('Training data:')\n",
    "print(df_train.info())\n",
    "print('Testing data:')\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
