{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9f2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f30980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FareForecastingModel(nn.Module):\n",
    "    def __init__(self, num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers):\n",
    "        super(FareForecastingModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for pick-up and drop-off\n",
    "        self.pickup_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        self.dropoff_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        \n",
    "        # LSTM for modeling temporal sequence\n",
    "        # Suppose our input for LSTM is the concatenation of embeddings + numeric features at each time step\n",
    "        # The input dimension for LSTM: 2*embedding_dim + num_numeric_features\n",
    "        lstm_input_dim = 2 * embedding_dim + num_numeric_features\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_dim, hidden_size=lstm_hidden_dim, \n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to produce the forecast\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, pickup_ids, dropoff_ids, numeric_seq):\n",
    "        # pickup_ids, dropoff_ids are assumed to have shape (batch_size, seq_length)\n",
    "        # numeric_seq has shape (batch_size, seq_length, num_numeric_features)\n",
    "        \n",
    "        # Get embeddings (result shape: (batch_size, seq_length, embedding_dim))\n",
    "        pickup_emb = self.pickup_embedding(pickup_ids)\n",
    "        dropoff_emb = self.dropoff_embedding(dropoff_ids)\n",
    "        \n",
    "        # Concatenate embeddings with numeric features along last dimension\n",
    "        # New shape: (batch_size, seq_length, 2*embedding_dim + num_numeric_features)\n",
    "        lstm_input = torch.cat((pickup_emb, dropoff_emb, numeric_seq), dim=-1)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        # For simplicity, predict using the output at the final time step\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Forecast output\n",
    "        forecast = self.fc(final_output)\n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9db630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Functions\n",
    "\n",
    "def circular_encoder(df):\n",
    "    # Encode dow and hour as sin and cos\n",
    "    \n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24.0)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24.0)\n",
    "    df.drop(['day_of_week', 'hour'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976bbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_amount_base_model(X_train, y_train, X_test, y_test):\n",
    "    # 1) remap your IDs exactly as before\n",
    "    unique_ids = sorted(set(X_train['PULocationID']).union(X_train['DOLocationID']))\n",
    "    id_to_index = {loc_id: idx for idx, loc_id in enumerate(unique_ids)}\n",
    "    for df in (X_train, X_test):\n",
    "        df['PULocationID'] = df['PULocationID'].map(id_to_index)\n",
    "        df['DOLocationID'] = df['DOLocationID'].map(id_to_index)\n",
    "\n",
    "    num_locations = len(unique_ids)\n",
    "    num_numeric  = X_train.shape[1] - 2\n",
    "\n",
    "    # 2) pick your device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 3) build & move model + loss\n",
    "    model     = FareForecastingModel(\n",
    "        num_locations=num_locations,\n",
    "        embedding_dim=8,\n",
    "        num_numeric_features=num_numeric,\n",
    "        lstm_hidden_dim=64,\n",
    "        lstm_layers=2\n",
    "    ).to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # 4) create four big tensors on GPU once\n",
    "    pu_train  = torch.tensor(X_train['PULocationID'].values).long().to(device)\n",
    "    do_train  = torch.tensor(X_train['DOLocationID'].values).long().to(device)\n",
    "    num_train = torch.tensor(\n",
    "        X_train.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    "    ).float().to(device)\n",
    "    y_train_t = torch.tensor(y_train.values).float().to(device)\n",
    "\n",
    "    # for eval later\n",
    "    pu_test   = torch.tensor(X_test['PULocationID'].values).long().to(device)\n",
    "    do_test   = torch.tensor(X_test['DOLocationID'].values).long().to(device)\n",
    "    num_test  = torch.tensor(\n",
    "        X_test.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    "    ).float().to(device)\n",
    "\n",
    "    # 5) training loop slices those GPU tensors directly\n",
    "    batch_size  = 32\n",
    "    num_samples = pu_train.size(0)\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(10):\n",
    "        print(f\"Starting epoch: {epoch}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            s = i * batch_size\n",
    "            e = s + batch_size\n",
    "\n",
    "            batch_pu   = pu_train[s:e].unsqueeze(1)\n",
    "            batch_do   = do_train[s:e].unsqueeze(1)\n",
    "            batch_nums = num_train[s:e].unsqueeze(1)\n",
    "            batch_y    = y_train_t[s:e]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_pu, batch_do, batch_nums)\n",
    "            loss  = criterion(preds.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch_size\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}  avg loss: {running_loss/num_samples:.4f}\")\n",
    "\n",
    "    print(\"Training Time:\", time.time() - start)\n",
    "    return model, (pu_test, do_test, num_test, y_test.values)\n",
    "\n",
    "def evaluate(model, test_tensors):\n",
    "    pu_test, do_test, num_test, y_test_vals = test_tensors\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(\n",
    "            pu_test.unsqueeze(1),\n",
    "            do_test.unsqueeze(1),\n",
    "            num_test.unsqueeze(1)\n",
    "        ).squeeze().cpu().numpy()\n",
    "\n",
    "    rmse = ((preds - y_test_vals)**2).mean()**0.5\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113119a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_train_base = pd.read_csv('data/train.csv')\n",
    "df_test_base = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_train = df_train_base.copy()\n",
    "df_test = df_test_base.copy()\n",
    "\n",
    "df_train = circular_encoder(df_train)\n",
    "df_test = circular_encoder(df_test)\n",
    "\n",
    "X_train= df_train.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_train = df_train['total_amount']\n",
    "\n",
    "X_test = df_test.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_test = df_test['total_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b293c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_arimax(X_train, y_train, X_test, y_test, order=(1, 1, 1)):\n",
    "    \"\"\"\n",
    "    Fits an ARIMA(p,d,q) with exogenous regressors:\n",
    "       y_t = ARIMA-errors + β · X_t\n",
    "    Returns the fitted model and out‑of‑sample forecasts.\n",
    "    \"\"\"\n",
    "    # 1) drop your PU/DO ID columns (or one‑hot / embed them if you really want to use them)\n",
    "    exog_train = X_train.drop(['PULocationID','DOLocationID'], axis=1)\n",
    "    exog_test  = X_test .drop(['PULocationID','DOLocationID'], axis=1)\n",
    "\n",
    "    # 2) build & fit\n",
    "    model = sm.tsa.statespace.SARIMAX(\n",
    "        endog=y_train,\n",
    "        exog=exog_train,\n",
    "        order=order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "    print(res.summary())\n",
    "\n",
    "    # 3) forecast the next len(y_test) points\n",
    "    forecast = res.get_forecast(\n",
    "        steps=len(y_test),\n",
    "        exog=exog_test\n",
    "    ).predicted_mean\n",
    "\n",
    "    # 4) evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "    print(f\"\\nARIMAX{order} RMSE: {rmse:.4f}\")\n",
    "    return res, forecast\n",
    "\n",
    "# --- how you’d call it:\n",
    "# choose (p,d,q) to your taste (you can also use pmdarima.auto_arima to select them)\n",
    "order = (1, 1, 1)\n",
    "\n",
    "arimax_model, arimax_preds = train_arimax(\n",
    "    X_train,       # your DataFrame of regressors\n",
    "    y_train,       # your Series of target fares\n",
    "    X_test,\n",
    "    y_test,\n",
    "    order=order\n",
    ")\n",
    "\n",
    "# ‘arimax_preds’ is a pandas Series aligned 0…len(y_test)-1\n",
    "# if you want an array:\n",
    "arimax_preds = arimax_preds.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d209154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_test_base['PULocationID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e956ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = total_amount_base_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fare_forecasting_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c29424",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = sorted(set(X_train['PULocationID']).union(X_train['DOLocationID']))\n",
    "\n",
    "# Load the model\n",
    "model = FareForecastingModel(\n",
    "    num_locations=len(unique_ids),\n",
    "    embedding_dim=8,\n",
    "    num_numeric_features=X_train.shape[1] - 2,\n",
    "    lstm_hidden_dim=64,\n",
    "    lstm_layers=2\n",
    ")\n",
    "model.load_state_dict(torch.load('fare_forecasting_model.pth',map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "device = 'cpu'\n",
    "unique_ids = sorted(set(X_train['PULocationID']).union(X_train['DOLocationID']))\n",
    "id_to_index = {loc_id: idx for idx, loc_id in enumerate(unique_ids)}\n",
    "for df in (X_train, X_test):\n",
    "    df['PULocationID'] = df['PULocationID'].map(id_to_index)\n",
    "    df['DOLocationID'] = df['DOLocationID'].map(id_to_index)\n",
    "pu_test   = torch.tensor(X_test['PULocationID'].values).long().to(device)\n",
    "do_test   = torch.tensor(X_test['DOLocationID'].values).long().to(device)\n",
    "num_test  = torch.tensor(\n",
    "    X_test.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    ").float().to(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, (pu_test, do_test, num_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d006ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example instantiation:\n",
    "num_locations = 265\n",
    "embedding_dim = 8\n",
    "num_numeric_features = 5\n",
    "lstm_hidden_dim = 64\n",
    "lstm_layers = 2\n",
    "\n",
    "model = FareForecastingModel(num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_proj4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
