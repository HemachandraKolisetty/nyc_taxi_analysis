{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9f2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f30980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FareForecastingModel(nn.Module):\n",
    "    def __init__(self, num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers):\n",
    "        super(FareForecastingModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for pick-up and drop-off\n",
    "        self.pickup_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        self.dropoff_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        \n",
    "        # LSTM for modeling temporal sequence\n",
    "        # Suppose our input for LSTM is the concatenation of embeddings + numeric features at each time step\n",
    "        # The input dimension for LSTM: 2*embedding_dim + num_numeric_features\n",
    "        lstm_input_dim = 2 * embedding_dim + num_numeric_features\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_dim, hidden_size=lstm_hidden_dim, \n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to produce the forecast\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, pickup_ids, dropoff_ids, numeric_seq):\n",
    "        # pickup_ids, dropoff_ids are assumed to have shape (batch_size, seq_length)\n",
    "        # numeric_seq has shape (batch_size, seq_length, num_numeric_features)\n",
    "        \n",
    "        # Get embeddings (result shape: (batch_size, seq_length, embedding_dim))\n",
    "        pickup_emb = self.pickup_embedding(pickup_ids)\n",
    "        dropoff_emb = self.dropoff_embedding(dropoff_ids)\n",
    "        \n",
    "        # Concatenate embeddings with numeric features along last dimension\n",
    "        # New shape: (batch_size, seq_length, 2*embedding_dim + num_numeric_features)\n",
    "        lstm_input = torch.cat((pickup_emb, dropoff_emb, numeric_seq), dim=-1)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        # For simplicity, predict using the output at the final time step\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Forecast output\n",
    "        forecast = self.fc(final_output)\n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9db630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Functions\n",
    "\n",
    "def circular_encoder(df):\n",
    "    # Encode dow and hour as sin and cos\n",
    "    \n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24.0)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24.0)\n",
    "    df.drop(['day_of_week', 'hour'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976bbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_amount_base_model(X_train, y_train, X_test, y_test):\n",
    "    # 1) remap your IDs exactly as before\n",
    "    unique_ids = sorted(set(X_train['PULocationID']).union(X_train['DOLocationID']))\n",
    "    id_to_index = {loc_id: idx for idx, loc_id in enumerate(unique_ids)}\n",
    "    for df in (X_train, X_test):\n",
    "        df['PULocationID'] = df['PULocationID'].map(id_to_index)\n",
    "        df['DOLocationID'] = df['DOLocationID'].map(id_to_index)\n",
    "\n",
    "    num_locations = len(unique_ids)\n",
    "    num_numeric  = X_train.shape[1] - 2\n",
    "\n",
    "    # 2) pick your device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 3) build & move model + loss\n",
    "    model     = FareForecastingModel(\n",
    "        num_locations=num_locations,\n",
    "        embedding_dim=8,\n",
    "        num_numeric_features=num_numeric,\n",
    "        lstm_hidden_dim=64,\n",
    "        lstm_layers=2\n",
    "    ).to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # 4) create four big tensors on GPU once\n",
    "    pu_train  = torch.tensor(X_train['PULocationID'].values).long().to(device)\n",
    "    do_train  = torch.tensor(X_train['DOLocationID'].values).long().to(device)\n",
    "    num_train = torch.tensor(\n",
    "        X_train.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    "    ).float().to(device)\n",
    "    y_train_t = torch.tensor(y_train.values).float().to(device)\n",
    "\n",
    "    # for eval later\n",
    "    pu_test   = torch.tensor(X_test['PULocationID'].values).long().to(device)\n",
    "    do_test   = torch.tensor(X_test['DOLocationID'].values).long().to(device)\n",
    "    num_test  = torch.tensor(\n",
    "        X_test.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    "    ).float().to(device)\n",
    "\n",
    "    # 5) training loop slices those GPU tensors directly\n",
    "    batch_size  = 32\n",
    "    num_samples = pu_train.size(0)\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(10):\n",
    "        print(f\"Starting epoch: {epoch}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            s = i * batch_size\n",
    "            e = s + batch_size\n",
    "\n",
    "            batch_pu   = pu_train[s:e].unsqueeze(1)\n",
    "            batch_do   = do_train[s:e].unsqueeze(1)\n",
    "            batch_nums = num_train[s:e].unsqueeze(1)\n",
    "            batch_y    = y_train_t[s:e]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_pu, batch_do, batch_nums)\n",
    "            loss  = criterion(preds.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch_size\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}  avg loss: {running_loss/num_samples:.4f}\")\n",
    "\n",
    "    print(\"Training Time:\", time.time() - start)\n",
    "    return model, (pu_test, do_test, num_test, y_test.values)\n",
    "\n",
    "def evaluate(model, test_tensors):\n",
    "    pu_test, do_test, num_test, y_test_vals = test_tensors\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(\n",
    "            pu_test.unsqueeze(1),\n",
    "            do_test.unsqueeze(1),\n",
    "            num_test.unsqueeze(1)\n",
    "        ).squeeze().cpu().numpy()\n",
    "\n",
    "    rmse = ((preds - y_test_vals)**2).mean()**0.5\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113119a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_train_base = pd.read_csv('data/train.csv')\n",
    "df_test_base = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_train = df_train_base.copy()\n",
    "df_test = df_test_base.copy()\n",
    "\n",
    "df_train = circular_encoder(df_train)\n",
    "df_test = circular_encoder(df_test)\n",
    "\n",
    "X_train= df_train.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_train = df_train['total_amount']\n",
    "\n",
    "X_test = df_test.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_test = df_test['total_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d209154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_test_base['PULocationID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e956ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0\n",
      "Epoch 01  avg loss: 9.5922\n",
      "Starting epoch: 1\n",
      "Epoch 02  avg loss: 9.2465\n",
      "Starting epoch: 2\n",
      "Epoch 03  avg loss: 9.2077\n",
      "Starting epoch: 3\n",
      "Epoch 04  avg loss: 9.1859\n",
      "Starting epoch: 4\n",
      "Epoch 05  avg loss: 9.2075\n",
      "Starting epoch: 5\n",
      "Epoch 06  avg loss: 9.1916\n",
      "Starting epoch: 6\n",
      "Epoch 07  avg loss: 9.1921\n",
      "Starting epoch: 7\n",
      "Epoch 08  avg loss: 9.1967\n",
      "Starting epoch: 8\n",
      "Epoch 09  avg loss: 9.1914\n",
      "Starting epoch: 9\n",
      "Epoch 10  avg loss: 9.1970\n",
      "Training Time: 14530.419337272644\n"
     ]
    }
   ],
   "source": [
    "model = total_amount_base_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f69bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.FareForecastingModel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0de55ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fare_forecasting_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c29424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FareForecastingModel(\n",
       "  (pickup_embedding): Embedding(262, 8)\n",
       "  (dropoff_embedding): Embedding(262, 8)\n",
       "  (lstm): LSTM(24, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = 'cpu'\n",
    "unique_ids = sorted(set(X_train['PULocationID']).union(X_train['DOLocationID']))\n",
    "id_to_index = {loc_id: idx for idx, loc_id in enumerate(unique_ids)}\n",
    "for df in (X_train, X_test):\n",
    "    df['PULocationID'] = df['PULocationID'].map(id_to_index)\n",
    "    df['DOLocationID'] = df['DOLocationID'].map(id_to_index)\n",
    "pu_test   = torch.tensor(X_test['PULocationID'].values).long().to(device)\n",
    "do_test   = torch.tensor(X_test['DOLocationID'].values).long().to(device)\n",
    "num_test  = torch.tensor(\n",
    "    X_test.drop(['PULocationID','DOLocationID'], axis=1).values\n",
    ").float().to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fcc0fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(model, (pu_test, do_test, num_test, y_test))\n",
      "Cell \u001b[0;32mIn[11], line 80\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, test_tensors)\u001b[0m\n\u001b[1;32m     78\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 80\u001b[0m     preds \u001b[39m=\u001b[39m model(\n\u001b[1;32m     81\u001b[0m         pu_test\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     82\u001b[0m         do_test\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     83\u001b[0m         num_test\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     84\u001b[0m     )\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     86\u001b[0m rmse \u001b[39m=\u001b[39m ((preds \u001b[39m-\u001b[39m y_test_vals)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRMSE: \u001b[39m\u001b[39m{\u001b[39;00mrmse\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mFareForecastingModel.forward\u001b[0;34m(self, pickup_ids, dropoff_ids, numeric_seq)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, pickup_ids, dropoff_ids, numeric_seq):\n\u001b[1;32m     20\u001b[0m     \u001b[39m# pickup_ids, dropoff_ids are assumed to have shape (batch_size, seq_length)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# numeric_seq has shape (batch_size, seq_length, num_numeric_features)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \n\u001b[1;32m     23\u001b[0m     \u001b[39m# Get embeddings (result shape: (batch_size, seq_length, embedding_dim))\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     pickup_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickup_embedding(pickup_ids)\n\u001b[1;32m     25\u001b[0m     dropoff_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropoff_embedding(dropoff_ids)\n\u001b[1;32m     27\u001b[0m     \u001b[39m# Concatenate embeddings with numeric features along last dimension\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m# New shape: (batch_size, seq_length, 2*embedding_dim + num_numeric_features)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    192\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    193\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx,\n\u001b[1;32m    194\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    195\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type,\n\u001b[1;32m    196\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq,\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse,\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cv_proj4/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "evaluate(model, (pu_test, do_test, num_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d006ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example instantiation:\n",
    "num_locations = 265\n",
    "embedding_dim = 8\n",
    "num_numeric_features = 5\n",
    "lstm_hidden_dim = 64\n",
    "lstm_layers = 2\n",
    "\n",
    "model = FareForecastingModel(num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_proj4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
