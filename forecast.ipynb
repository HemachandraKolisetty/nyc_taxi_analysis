{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9f2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f30980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FareForecastingModel(nn.Module):\n",
    "    def __init__(self, num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers):\n",
    "        super(FareForecastingModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for pick-up and drop-off\n",
    "        self.pickup_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        self.dropoff_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        \n",
    "        # LSTM for modeling temporal sequence\n",
    "        # Suppose our input for LSTM is the concatenation of embeddings + numeric features at each time step\n",
    "        # The input dimension for LSTM: 2*embedding_dim + num_numeric_features\n",
    "        lstm_input_dim = 2 * embedding_dim + num_numeric_features\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_dim, hidden_size=lstm_hidden_dim, \n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to produce the forecast\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, pickup_ids, dropoff_ids, numeric_seq):\n",
    "        # pickup_ids, dropoff_ids are assumed to have shape (batch_size, seq_length)\n",
    "        # numeric_seq has shape (batch_size, seq_length, num_numeric_features)\n",
    "        \n",
    "        # Get embeddings (result shape: (batch_size, seq_length, embedding_dim))\n",
    "        pickup_emb = self.pickup_embedding(pickup_ids)\n",
    "        dropoff_emb = self.dropoff_embedding(dropoff_ids)\n",
    "        \n",
    "        # Concatenate embeddings with numeric features along last dimension\n",
    "        # New shape: (batch_size, seq_length, 2*embedding_dim + num_numeric_features)\n",
    "        lstm_input = torch.cat((pickup_emb, dropoff_emb, numeric_seq), dim=-1)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        # For simplicity, predict using the output at the final time step\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Forecast output\n",
    "        forecast = self.fc(final_output)\n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9db630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Functions\n",
    "\n",
    "def circular_encoder(df):\n",
    "    # Encode dow and hour as sin and cos\n",
    "    \n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7.0)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24.0)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24.0)\n",
    "    df.drop(['day_of_week', 'hour'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976bbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_amount_base_model(X_train, X_test, y_train, y_test):\n",
    "    unique_ids = sorted(set(X_train['PULocationID'].unique()).union(set(X_train['DOLocationID'].unique())))\n",
    "    id_to_index = {loc_id: idx for idx, loc_id in enumerate(unique_ids)}\n",
    "    \n",
    "    X_train['PULocationID'] = X_train['PULocationID'].map(id_to_index)\n",
    "    X_train['DOLocationID'] = X_train['DOLocationID'].map(id_to_index)\n",
    "    X_test['PULocationID']  = X_test['PULocationID'].map(id_to_index)\n",
    "    X_test['DOLocationID']  = X_test['DOLocationID'].map(id_to_index)\n",
    "    \n",
    "    num_locations = len(unique_ids)\n",
    "\n",
    "    model = FareForecastingModel(\n",
    "        num_locations=num_locations,  # Example: number of unique locations\n",
    "        embedding_dim=8,\n",
    "        num_numeric_features=X_train.shape[1] - 2,  # Exclude pickup and dropoff IDs\n",
    "        lstm_hidden_dim=64,\n",
    "        lstm_layers=2\n",
    "    )\n",
    "    start = time.time()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        for i in range(num_batches):\n",
    "            batch_X = X_train[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_y = y_train[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            # print(batch_X.shape)\n",
    "\n",
    "            # Convert to PyTorch tensors\n",
    "            pickup_ids = torch.tensor(batch_X['PULocationID'].values).long().unsqueeze(1)\n",
    "            dropoff_ids = torch.tensor(batch_X['DOLocationID'].values).long().unsqueeze(1)\n",
    "            numeric_features = torch.tensor(batch_X.drop(['PULocationID', 'DOLocationID'], axis=1).values).float().unsqueeze(1)\n",
    "\n",
    "            batch_y_tensor = torch.tensor(batch_y.values).float()\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(pickup_ids, dropoff_ids, numeric_features)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), batch_y_tensor)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Training Time: {end - start} seconds\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pickup_ids = torch.tensor(X_test['PULocationID'].values).long().unsqueeze(1)\n",
    "        dropoff_ids = torch.tensor(X_test['DOLocationID'].values).long().unsqueeze(1)\n",
    "        numeric_features = torch.tensor(X_test.drop(['PULocationID', 'DOLocationID'], axis=1).values).float().unsqueeze(1)\n",
    "\n",
    "        predictions = model(pickup_ids, dropoff_ids, numeric_features)\n",
    "        predictions = predictions.squeeze().numpy()\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((predictions - y_test.values) ** 2))\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    return model, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113119a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_train_base = pd.read_csv('data/train.csv')\n",
    "df_test_base = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_train = df_train_base.copy()\n",
    "df_test = df_test_base.copy()\n",
    "\n",
    "df_train = circular_encoder(df_train)\n",
    "df_test = circular_encoder(df_test)\n",
    "\n",
    "X_train= df_train.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_train = df_train['total_amount']\n",
    "\n",
    "X_test = df_test.drop(['travel_time', 'total_amount'], axis=1)\n",
    "y_test = df_test['total_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d209154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_test_base['PULocationID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e956ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n",
      "Training Time: 10848.42094707489 seconds\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['PULocationID', 'DOLocationID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_amount_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 73\u001b[0m, in \u001b[0;36mtotal_amount_base_model\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     71\u001b[0m pickup_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPULocationID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     72\u001b[0m dropoff_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOLocationID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPULocationID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDOLocationID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(pickup_ids, dropoff_ids, numeric_features)\n\u001b[1;32m     76\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_proj4/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_proj4/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_proj4/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_proj4/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PULocationID', 'DOLocationID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "model, rmse = total_amount_base_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d006ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example instantiation:\n",
    "num_locations = 265\n",
    "embedding_dim = 8\n",
    "num_numeric_features = 5\n",
    "lstm_hidden_dim = 64\n",
    "lstm_layers = 2\n",
    "\n",
    "model = FareForecastingModel(num_locations, embedding_dim, num_numeric_features, lstm_hidden_dim, lstm_layers)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_proj4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
